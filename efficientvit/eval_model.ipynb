{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob,os\n",
    "import torch\n",
    "from simple_train import load_model\n",
    "from eval_model import get_image_paths, single_image_inference, infer_folder, evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training folders: 10\n",
      "Number of validation folders: 10\n",
      "Number of test images: 4385\n",
      "Number of training images: 37607\n",
      "Number of validation images: 16132\n"
     ]
    }
   ],
   "source": [
    "TRAIN_FOLDER = r'D:\\Work\\Dataset\\Misahub-CapsuleVision-Dataset\\Dataset\\training'\n",
    "VAL_FOLDER   =   r'D:\\Work\\Dataset\\Misahub-CapsuleVision-Dataset\\Dataset\\validation'\n",
    "TEST_FOLDER  = r'D:\\Work\\Challenges\\Misahub-Capsule-Vision\\datasets\\CapsuleVisionTestDataset\\Testing set\\Testing set\\Images'\n",
    "\n",
    "train_paths, val_paths, test_image_paths = get_image_paths(TRAIN_FOLDER, \n",
    "                                                           VAL_FOLDER,\n",
    "                                                           TEST_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters: 11447818\n",
      "Number of non-trainable parameters: 49090208\n",
      "Model path : D:\\Work\\Challenges\\Misahub-Capsule-Vision\\models\\efficientvit\\ch_checkpoints\\22\\EfficientViT-L2-bestvalf1-23-0.9065.pt\n",
      "Model Loaded ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4385 [00:00<?, ?it/s]c:\\Users\\girin\\anaconda3\\envs\\torchvision_odd\\lib\\site-packages\\torch\\nn\\modules\\conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "100%|██████████| 4385/4385 [02:50<00:00, 25.69it/s]\n"
     ]
    }
   ],
   "source": [
    "best_model = r'D:\\Work\\Challenges\\Misahub-Capsule-Vision\\models\\efficientvit\\ch_checkpoints\\22\\EfficientViT-L2-bestvalf1-23-0.9065.pt'\n",
    "\n",
    "model = load_model(num_classes=10)\n",
    "checkpoint = torch.load(best_model)\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "\n",
    "print(f'Model path : {best_model}')\n",
    "print('Model Loaded ..')\n",
    "\n",
    "df = infer_folder(model,\n",
    "                  test_image_paths, \n",
    "                  type='test',\n",
    "                  device=device)\n",
    "    \n",
    "\n",
    "# === Evaluation model if its training or validation dataset ===\n",
    "# rep = evaluate_model(df)\n",
    "\n",
    "# print(rep['classification_report'])  \n",
    "# print(f'Mean AUC: {rep[\"mean_auc\"]:.2f}')\n",
    "# print(f'Balanced Accuracy: {rep[\"balanced_accuracy\"]:.2f}')\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('test_sub.xlsx',\n",
    "            index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# single_image_inference(model,\n",
    "#                        val_paths[300]['image_path'],\n",
    "#                        device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = infer_folder(model,\n",
    "                  val_paths, \n",
    "                  type='val',\n",
    "                  device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('model_weighloss_val_preds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep = evaluate_model(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rep['classification_report'])\n",
    "print(f'Mean AUC: {rep[\"mean_auc\"]:.3f}')\n",
    "print(f'Balanced Accuracy: {rep[\"balanced_accuracy\"]:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, learning_rate=0.01):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weights = np.random.randn(2)  # Initialize weights randomly\n",
    "    \n",
    "    def _relu(self, z):\n",
    "        return np.maximum(z, 0)\n",
    "    \n",
    "    def _relu_derivative(self, z):\n",
    "        return np.where(z > 0, 1, 0)\n",
    "    \n",
    "    def forward_propagate(self, X):\n",
    "        z = np.dot(X, self.weights)\n",
    "        return self._relu(z)\n",
    "    \n",
    "    def backward_propagate(self, X, y, y_pred):\n",
    "        d_output = 2 * (y_pred - y)\n",
    "        d_relu = d_output * self._relu_derivative(y_pred)\n",
    "        d_weights = np.dot(X.T, d_relu)\n",
    "        return d_weights\n",
    "    \n",
    "    def update_weights(self, d_weights):\n",
    "        self.weights -= self.learning_rate * d_weights\n",
    "    \n",
    "    def train(self, X, y, epochs=1000):\n",
    "        X_with_bias = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "        \n",
    "        for _ in range(epochs):\n",
    "            y_pred = self.forward_propagate(X_with_bias)\n",
    "            d_weights = self.backward_propagate(X_with_bias, y, y_pred)\n",
    "            self.update_weights(d_weights)\n",
    "        \n",
    "        return self.weights\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_with_bias = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "        return self.forward_propagate(X_with_bias)\n",
    "\n",
    "# Generate sample data\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(100, 1)\n",
    "y = 3 * X + 2 + np.random.randn(100, 1) / 1.5\n",
    "\n",
    "# Train the model\n",
    "nn = NeuralNetwork()\n",
    "weights = nn.train(X, y)\n",
    "\n",
    "print(f\"Final weights: {weights}\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred = nn.predict(X)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = np.mean((y - y_pred) ** 2)\n",
    "r_squared = 1 - (np.sum((y - y_pred) ** 2) / np.sum((y - np.mean(y)) ** 2))\n",
    "\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "print(f\"R-squared: {r_squared:.4f}\")\n",
    "\n",
    "# Visualize the results\n",
    "plt.scatter(X, y, label='Actual')\n",
    "plt.plot(X, y_pred, color='red', label='Predicted')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Linear Regression using Neural Network')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchvision_odd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
